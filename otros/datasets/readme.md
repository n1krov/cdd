# ğŸ“‚ Carpeta `Datasets` â€” Curso de Ciencia de Datos (5Âº aÃ±o)

Â¡Bienvenido/a! AquÃ­ iremos subiendo **todos los conjuntos de datos (datasets)** que usemos en la materia:  
- **Aportes de la cÃ¡tedra** (material oficial para prÃ¡cticas y exÃ¡menes).  
- **Aportes de alumnos** (datasets propios para laboratorios y proyectos).  

> _Regla de oro_: si el archivo pesa mÃ¡s que la cafetera del laboratorio, mejor **subÃ­ un enlace** y una **instrucciÃ³n reproducible** (API/CLI) para descargarlo. ğŸ§ªâ˜•

---

## ğŸ¯ Objetivos de esta carpeta
- Centralizar los datasets usados en clase y proyectos.
- Documentar **origen, licencia y versiÃ³n** de cada dataset.
- Fomentar buenas prÃ¡cticas de **reproducibilidad** (scripts de descarga/limpieza).
- Evitar â€œdataset huÃ©rfanosâ€: todo dataset debe tener su **ficha**.

---

## ğŸ§± Estructura sugerida

```
Datasets/
â”œâ”€ README.md                  # este archivo
â”œâ”€ catalogo.csv               # Ã­ndice opcional de datasets (nombre, origen, licencia, versiÃ³n)
â”œâ”€ oficiales/                 # datasets provistos por la cÃ¡tedra
â”‚  â”œâ”€ 12 Aug 2025-ejemplo/       
â”‚  â”‚  â”œâ”€ data/               # archivos .csv/.parquet/.json
â”‚  â”‚  â”œâ”€ metadata/           # README_origen.md, LICENSE, schema.json
â”‚  â”‚  â””â”€ notebooks/          # EDA y limpieza
â””â”€ alumnos/
   â”œâ”€ equipo-01-nombre-dataset/
   â”‚  â”œâ”€ data/
   â”‚  â”œâ”€ metadata/
   â”‚  â””â”€ notebooks/
```

**Convenciones de nombre**: `equipo-<NN>-<slug-dataset>` o `{AAAA-MM-DD}-<slug>` para oficiales.

---

## ğŸ“ Ficha obligatoria de cada dataset

IncluÃ­ un `metadata/README_origen.md` con:
- **Nombre**:  
- **Autor/es**:  
- **Origen/URL**:  
- **Fecha de descarga**:  
- **Licencia** (ej.: CC BY 4.0, ODbL, Public Domain).  
- **VersiÃ³n** (nÃºmero o commit/tag).  
- **DescripciÃ³n breve** (3â€“5 lÃ­neas).  
- **Esquema** (columnas, tipos, unidades).  
- **Pasos de preparaciÃ³n** (script o notebook).  
- **Limitaciones y sesgos conocidos**.  

> Pro tip: agregÃ¡ un `schema.json` o `table_schema.json` (frictionless) si el dataset es tabular.

---

## ğŸ§  Kaggle: Â¿quÃ© es y cÃ³mo lo usaremos?

**Kaggle** es una plataforma de Google para Ciencia de Datos con:  
- **Datasets pÃºblicos**, **Kaggle Notebooks**, **API/CLI**, **modelos** y **competencias**.  
- Excelente para **encontrar** y **compartir** datos, y para ejecutar notebooks en la nube.

### ğŸ‘‰ CÃ³mo lo usaremos en la materia
1. **BÃºsqueda y selecciÃ³n** de datasets reales para prÃ¡cticas.  
2. **Descarga reproducible** con la **Kaggle API** (nada de â€œme lo pasÃ¡s por WhatsAppâ€).  
3. **CitaciÃ³n del origen** y **respeto de licencias**.  
4. PublicaciÃ³n de **subsets limpios** de producciÃ³n del curso (si la licencia lo permite).

### ğŸš€ Pasos rÃ¡pidos para usar la API de Kaggle
1. Crear cuenta en Kaggle y **generar token** (`kaggle.json`) en _Account â†’ API â†’ Create New Token_.  
2. Guardar `~/.kaggle/kaggle.json` (Linux/Mac) o `%HOMEPATH%\.kaggle\kaggle.json` (Windows). **No lo comitees**.  
3. Instalar la CLI:
   ```bash
   pip install kaggle
   kaggle --help
   ```
4. Descargar un dataset (ejemplos):
   ```bash
   # YouTube Trending (por paÃ­s)
   kaggle datasets download -d datasnaek/youtube-new -p ./Datasets/oficiales/youtube_trending/ -u -o

   # Netflix Movies & TV Shows
   kaggle datasets download -d shivamb/netflix-shows -p ./Datasets/oficiales/netflix/ -u -o

   # US Accidents 2016â€“2023 (muy grande)
   kaggle datasets download -d sobhanmoosavi/us-accidents -p ./Datasets/oficiales/us_accidents/ -u -o
   ```
   _Flags Ãºtiles_: `-p` (destino), `-u` (descomprimir), `-o` (sobrescribir), `-f` (archivo especÃ­fico).

> **Licencias**: verificÃ¡ siempre la licencia en la pÃ¡gina del dataset. Si es restrictiva, **no re-publicar** los datos crudos; subÃ­ solo scripts de preparaciÃ³n.

---

## ğŸŒŸ 3 ejemplos llamativos en Kaggle (para inspirarte)

- **US Accidents (2016â€“2023)** â€” dataset masivo de siniestros viales en EE.â€¯UU., ideal para geodatos, series temporales y clima.  
  URL: https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents

- **Trending YouTube Video Statistics** â€” mÃ©tricas diarias de videos en tendencia (varios paÃ­ses), excelente para _EDA_ y scraping-aware pipelines.  
  URL: https://www.kaggle.com/datasets/datasnaek/youtube-new

- **Netflix Movies and TV Shows** â€” catÃ¡logo (periÃ³dicamente actualizado) para anÃ¡lisis de contenido y _recommenders_.  
  URL: https://www.kaggle.com/datasets/shivamb/netflix-shows

### ğŸ† Â¿El dataset â€œmÃ¡s descargadoâ€?
Kaggle **no publica un ranking oficial global** de descargas. Entre los datasets con contador visible, **Trending YouTube Video Statistics** figura con **â‰ˆ 280â€¯000 descargas** (consultado el 12 Aug 2025). TÃ³menlo como **referencia**, no como rÃ©cord absoluto, porque las cifras varÃ­an por versiÃ³n y espejo.

---

## ğŸŒ 10 sitios populares (acceso libre) para descargar datasets

1. **UCI Machine Learning Repository** â€” clÃ¡sicos de ML, gran variedad tabular.  
   https://archive.ics.uci.edu/

2. **Google Dataset Search** â€” buscador vertical de datasets en la web.  
   https://datasetsearch.research.google.com/

3. **Registry of Open Data on AWS** â€” datos abiertos alojados en Amazon (S3, etc.).  
   https://registry.opendata.aws/

4. **Data.gov (EE.â€¯UU.)** â€” portal de datos abiertos del gobierno federal.  
   https://data.gov/

5. **data.europa.eu (UE)** â€” portal oficial de datos abiertos de la UniÃ³n Europea.  
   https://data.europa.eu/

6. **World Bank Open Data** â€” indicadores econÃ³micos y sociales globales.  
   https://data.worldbank.org/

7. **OECD Data** â€” estadÃ­sticas comparadas de paÃ­ses OCDE.  
   https://www.oecd.org/en/data.html

8. **Our World in Data** â€” compilaciones curadas sobre temas globales (CSV accesibles).  
   https://ourworldindata.org/

9. **OpenML** â€” repositorio y API para datasets estandarizados de ML.  
   https://www.openml.org/

10. **Harvard Dataverse** â€” repositorio acadÃ©mico con DOIs para citar.  
    https://dataverse.harvard.edu/

---

## âœ… Buenas prÃ¡cticas (checklist rÃ¡pido)

- [ ] IncluÃ­ **ficha** con origen, licencia, fecha y versiÃ³n.  
- [ ] SubÃ­ **scripts de descarga/limpieza** (no subas binarios gigantes si hay fuente pÃºblica).  
- [ ] DocumentÃ¡ **pasos para reproducir** (README + `requirements.txt`).  
- [ ] AnonimizÃ¡ datos sensibles (cumplimiento y Ã©tica > curiosidad).  
- [ ] **No** subas `kaggle.json` ni claves a Git.  
- [ ] Si tu dataset pesa >100â€¯MB, considerÃ¡ **Parquet** o compresiÃ³n.  

---

## ğŸ¤¹â€â™€ï¸ Nota final con chiste malo
Â¿SabÃ­as que algunos datasets tienen **outliers** porqueâ€¦ simplemente **no encajan**? ğŸ˜…  
Tranquilo: para eso estÃ¡n tus skills de limpieza y validaciÃ³n.

---

### CrÃ©ditos y referencias
- Kaggle Docs â€” Datasets: https://www.kaggle.com/docs/datasets  
- Kaggle Docs â€” Public API/CLI: https://www.kaggle.com/docs/api  
- Kaggle API (repo oficial): https://github.com/Kaggle/kaggle-api  
- Datasets de ejemplo: ver enlaces arriba en cada viÃ±eta.

