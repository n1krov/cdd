---
title: "Building Medallion Architectures - Designing with Delta Lake and Spark"
subtitle: "Resumen del cap√≠tulo 1"
author: "Piethein Strengholt"
date: \today
geometry: margin=1.6in
colorlinks: true
header-includes:
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
  - \usepackage{graphicx}
	# - \setkeys{Gin}{width=0.95\textwidth}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{tabularx}
  - \usepackage{array}
  - \renewcommand{\arraystretch}{1.5}
  
  # neutralizamos tightlist y ajustamos espaciado de listas
  - \let\tightlist\relax
  - \usepackage{enumitem}
  - \setlist[itemize,enumerate]{itemsep=1\baselineskip, topsep=1\baselineskip}
  
  # estilo rosado p√°lido con fuente aclarada
  - \usepackage[most]{tcolorbox}
  - |
    \newtcolorbox{noteBox}{
      colback=red!5!white,
      colframe=red!30!black,
      coltext=black!70,        % color del texto menos saturado
      arc=4pt,
      left=6pt, right=6pt, top=4pt, bottom=4pt,
      boxrule=0.5pt,
      breakable
    }
  - |
    \renewenvironment{quote}{\begin{noteBox}}{\end{noteBox}}

  # --- Caption sin numeraci√≥n para figuras ---
  - \usepackage{caption}
  - \captionsetup[figure]{labelformat=empty}
---

# Cap√≠tulo 1. La Evoluci√≥n de la Arquitectura de Datos

Crear una arquitectura de datos robusta es uno de los aspectos m√°s desafiantes de la gesti√≥n de datos. El proceso abarca desde la recolecci√≥n hasta la transformaci√≥n, distribuci√≥n y consumo final, variando seg√∫n la gobernanza, herramientas, perfil de riesgo y madurez de la organizaci√≥n.

A pesar de estas diferencias, el autor propone una met√°fora fundamental para estructurar cualquier estrategia de datos: el **Dise√±o de Arquitectura de Tres Capas**.

![Figura 1-1: El dise√±o de arquitectura de tres capas](f11%203.png)

Este dise√±o consta de:

### 1. üßë‚Äçüíª Capa 1: Proveedores de Datos (**Data Providers**)

- **¬øQu√© es?** Son los **puntos de origen** de todos los datos.
    
- **En la pr√°ctica:** Es donde est√° la informaci√≥n bruta: tus bases de datos operacionales, los archivos de texto, los datos que vienen de sensores, los registros de aplicaciones, etc.
    
- **Desaf√≠o:** Vienen en **muchos formatos y ubicaciones diferentes** (la "mezcla de tipos de datos, formatos y ubicaciones dispersas").

### Capa 2: Capa de Distribuci√≥n (**Distribution Layer**)

- **¬øQu√© es?** Es el **sistema de transporte y procesamiento**. Es la plataforma donde los datos se mueven, se limpian, se transforman y se preparan.
    
- **En la pr√°ctica:** Aqu√≠ es donde se usan herramientas complejas (como **Apache Spark**) para integrar y procesar grandes vol√∫menes de datos crudos, convirti√©ndolos en algo √∫til.
    
- **Desaf√≠o:** Es la parte **m√°s compleja** porque hay much√≠simas tecnolog√≠as diferentes para hacer esta integraci√≥n (el "Modern Data Stack").

### 3. üìä Capa 3: Consumidores de Datos (**Data Consumers**)

- **¬øQu√© es?** Son los **usuarios finales** y las **aplicaciones** que necesitan la informaci√≥n lista para tomar decisiones.
    
- **En la pr√°ctica:** Son los paneles de control (**BI**), los modelos de **Machine Learning (ML)** para hacer predicciones, y los sistemas de **Inteligencia Artificial (AI)** que automatizan acciones.


### Capa Transversal: üõ°Ô∏è Metadatos y Gobernanza

- **¬øQu√© es?** Es la **supervisi√≥n y las reglas** que controlan todas las capas.
    
- **En la pr√°ctica:** Se asegura de que los datos sean **seguros**, que sean de **calidad** (no tengan errores) y que todo el mundo sepa **qu√© significa** cada dato (metadatos).
    

### El Desaf√≠o Actual

El texto menciona el **"Modern Data Stack"** como el problema clave hoy en d√≠a.

- **Problema:** Este "Stack" est√° hecho de **muchas herramientas individuales** (para almacenamiento, procesamiento, etc.) que no siempre se hablan bien entre s√≠. Esto hace que sea muy **dif√≠cil y costoso** para las empresas crear una plataforma de distribuci√≥n funcional.
    
- **Soluci√≥n:** La **Arquitectura Medallion** (que usa tecnolog√≠as como Spark y Delta Lake) surge como una forma de **estandarizar** esta Capa de Distribuci√≥n, simplificando el proceso y mejorando la calidad de los datos. En resumen: **Los datos nacen (Proveedores), se preparan (Distribuci√≥n) y se usan (Consumidores), todo bajo la vigilancia de la Gobernanza.**

## ¬øQu√© es una Arquitectura Medallion?

Es un patr√≥n de dise√±o de datos utilizado para organizar l√≥gicamente los datos, generalmente en un *Lakehouse*. Su objetivo es mejorar incremental y progresivamente la estructura y calidad de los datos a medida que fluyen a trav√©s de tres capas principales.

Es una forma de **organizar el flujo de datos** en tu sistema, dividi√©ndolo en **tres niveles de calidad y refinamiento** (como si fueran medallas) que se construyen incrementalmente.

El objetivo es **mejorar progresivamente los datos** a medida que pasan de una capa a la siguiente, asegurando que el producto final sea de **alta calidad y f√°cil de usar**.

| **Capa**   | **Funci√≥n Clave**                                                                                                                               | **Medalla**   |
| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| **Bronze** | Es la **Zona de Datos Crudos (Raw Data)**. Los datos se almacenan **tal cual** como vienen de la fuente.                                        | üü† **Bronce** |
| **Silver** | Es la **Zona de Limpieza y Estandarizaci√≥n**. Los datos se **limpian**, se **validan** y se **estructuran** (se les da un formato consistente). | ‚ö™ **Plata**   |
| **Gold**   | Es la **Zona de Datos de Negocio**. Los datos se **agregan**, se **resumen** y se **optimizan** para la anal√≠tica y los reportes finales.       | üü° **Oro**    |

![Figura 1-2: Una arquitectura Medallion, que organiza los datos en tres capas, mejorando la estructura y calidad de los datos a medida que avanza a trav√©s de las capas](f12%202.png)

Aunque las etiquetas son intuitivas, muchas empresas fallan al modelar sus datos dentro de estas capas, confundiendo objetivos y estrategias de gobernanza. Para entender c√≥mo aplicar esto correctamente, es vital comprender primero la historia de las arquitecturas de datos.

## Una Breve Historia de la Arquitectura de Data Warehouse

En los a√±os 90, el **Data Warehousing** surgi√≥ para crear una "versi√≥n √∫nica de la verdad" integrando datos en una colecci√≥n unificada.

![Figura 1-3: Arquitectura t√≠pica de un data warehouse](f13%202.png)


El Data Warehouse (DW) surgi√≥ para crear un **"Versi√≥n √önica de la Verdad"** (Single Source of Truth), integrando datos de varias fuentes para el an√°lisis. La arquitectura t√≠pica se compone de cuatro etapas en un flujo de izquierda a derecha.

#### La Cadena de Flujo del DW:

1. **Sistemas OLTP** (Fuentes)
    
2. **Staging Area** (Preparaci√≥n)
    
3. **Data Warehouse** (Almac√©n Central)
    
4. **Data Marts** (Presentaci√≥n)
    

### üìå Diferencia Clave: OLTP vs. OLAP

La principal diferencia en la arquitectura de datos es el prop√≥sito: transacciones vs. an√°lisis.

|**Caracter√≠stica**|**OLTP (Online Transaction Processing)**|**OLAP (Online Analytical Processing)**|
|---|---|---|
|**Prop√≥sito**|Operaciones diarias, transacciones (Ej: Compra en l√≠nea, retiro bancario).|An√°lisis de tendencias, toma de decisiones (Ej: Reportes de ventas, predicciones).|
|**Dise√±o**|**Normalizado** (3NF). Reduce la redundancia, optimiza escrituras.|**Desnormalizado** (Esquema de Estrella). Optimiza lecturas complejas (_joins_).|
|**Operaci√≥n**|Cargas de trabajo predecibles: Leer, actualizar, borrar un registro.|Consultas complejas que acceden a grandes vol√∫menes de datos.|
|**Propiedades**|Requiere **ACID** (Atomicidad, Consistencia, Aislamiento, Durabilidad).|No requiere ACID en la misma medida. Prioriza velocidad y agregaci√≥n.|

> [!note] Problema del OLTP para Anal√≠tica
> 
> Los sistemas OLTP est√°n dise√±ados para escribir r√°pido. Extraer datos para an√°lisis profundo (que requiere muchos joins y datos hist√≥ricos) los sobrecarga, y suelen perder historia al borrar datos antiguos.

### üóÑÔ∏è Normalizaci√≥n y Desnormalizaci√≥n

- **Normalizaci√≥n:** T√©cnica de dise√±o de DB para **reducir la redundancia** y mejorar la integridad de los datos. Es eficiente para las escrituras (insertar/actualizar).
    
    - **Ejemplo:** Tener una tabla `Clientes` separada de una tabla `Pedidos`, conectadas por un ID.
        
- **Desnormalizaci√≥n:** **Introduce redundancia intencional** (duplica datos) para mejorar el rendimiento de las consultas (lecturas), evitando costosos _joins_. Es la t√©cnica principal en Data Warehousing (OLAP).
    
    - **Ejemplo:** En la tabla `Pedidos` se copia directamente el `Nombre_Cliente` y la `Direcci√≥n` para no tener que hacer _join_ con la tabla `Clientes`.
        

### üè≠ El √Årea de Staging (Staging Area)

Es la zona de "aterrizaje" de los datos crudos antes de ser transformados y cargados al Data Warehouse (la etapa **E**xtracci√≥n de **E**TL).

- **Funci√≥n Clave:**
    
    - **A√≠sla** las fuentes (OLTP) del proceso de transformaci√≥n.
        
    - Sirve como **respaldo** de los datos extra√≠dos (copias hist√≥ricas).
        
- **Contenido:** Generalmente bases de datos relacionales temporales o almacenamiento de archivos de bajo costo.
    


### üó∫Ô∏è Metodolog√≠as de Dise√±o de Data Warehouse

Existen dos enfoques principales para construir un Data Warehouse, definidos por la jerarqu√≠a de construcci√≥n.

#### 1. Metodolog√≠a Inmon (Top-Down)

- **Creador:** Bill Inmon.
    
- **Enfoque:** De **Arriba hacia Abajo** (Top-Down). Primero se construye el gran almac√©n central, luego los subconjuntos para los usuarios.
    
- **Flujo:**
    
    1. Cargar datos a un **Enterprise Data Warehouse (EDW)** central.
        
    2. El EDW usa un modelo **normalizado (3NF)**.
        
    3. Crear **Data Marts** departamentales _derivados_ del EDW, utilizando modelos desnormalizados (esquema de estrella) para reportes.
        

> [!warning] Desventaja de Inmon
> 
> Requiere un doble esfuerzo de ETL: primero para llevar los datos crudos al EDW normalizado, y luego para llevarlos del EDW a los Data Marts desnormalizados.


![Figura 1-4: El enfoque Inmon; un dise√±o de arriba hacia abajo donde primero se construye un almac√©n de datos centralizado y luego se crean data marts a partir de este almac√©n central](f14%201.png)

#### 2. Metodolog√≠a Kimball (Bottom-Up)

- **Creador:** Ralph Kimball.
    
- **Enfoque:** De **Abajo hacia Arriba** (Bottom-Up). Se construyen Data Marts que luego se integran para formar el DW.
    
- **Modelo:** Utiliza el **Modelo Dimensional (Esquema de Estrella)** como est√°ndar de integraci√≥n.
    
    - **Tablas de Hechos:** Contienen las m√©tricas (lo que se mide: ventas, clics).
        
    - **Tablas de Dimensiones:** Contienen el contexto (qui√©n, qu√©, d√≥nde, cu√°ndo: cliente, producto, tiempo).
        
![Figura 1-5: La metodolog√≠a Kimball; un enfoque de abajo hacia arriba para construir el data warehouse](f15%201.png)

##### Conceptos Clave de Kimball

- **Dimensiones Conformadas (Conformed Dimensions):** Tablas de dimensiones (ej. `Tiempo`, `Cliente`) que son **id√©nticas** o subconjuntos estandarizados entre diferentes Data Marts. Esto permite que los reportes de Ventas y Marketing puedan "hablar el mismo idioma".
    
- **SCDs (Slowly Changing Dimensions):** Estrategias para registrar los **cambios hist√≥ricos** en las tablas de dimensiones (ej. cuando un cliente cambia de direcci√≥n).
    

##### Tabla: Tipos de SCD

|**Tipo**|**Nombre**|**Estrategia**|**P√©rdida de Historia**|**Tama√±o de Tabla**|
|---|---|---|---|---|
|**SCD1**|Sobrescribir (Overwrite)|Actualiza el registro existente con el nuevo valor.|**S√≠** (Pierde la historia anterior).|Peque√±o.|
|**SCD2**|A√±adir nueva fila (Add row)|Crea un **nuevo registro** para el cambio, manteniendo el viejo. Usa fechas de vigencia.|**No** (Mantiene historia completa).|Grande (Aumenta con cada cambio).|
|**SCD3**|A√±adir nueva columna|Agrega una columna para el valor anterior (ej. `Direcci√≥n_Anterior`).|**S√≠** (Solo guarda una versi√≥n anterior limitada).|Moderado.|

> [!example] Ejemplo SCD2 (A√±adir nueva fila)
> 
> Un cliente vive en Madrid hasta 2024-01-01.
> 
> |**ID_Cliente_Surrogada**|**Nombre**|**Ciudad**|**Fecha_Inicio_Vigencia**|**Fecha_Fin_Vigencia**|
> |---|---|---|---|---|
> |100|Juan|Madrid|2020-01-01|2024-01-01|
> |101|Juan|Barcelona|2024-01-02|NULO|

### üõë Conclusiones y Limitaciones del DW Tradicional

Los Data Warehouses tradicionales son muy efectivos para datos estructurados y consultas **OLAP** r√°pidas. Sin embargo, tienen limitaciones importantes en la era moderna:

- **Escalabilidad Costosa:** Escalar la capacidad (verticalmente) es muy caro y tiene l√≠mites f√≠sicos.
    
- **No Aptos para Datos Modernos:** No manejan bien los datos **no estructurados** (im√°genes, video) ni los semi-estructurados (JSON, logs), y tampoco est√°n optimizados para cargas de trabajo de **Machine Learning (ML)**.


## Una Breve Historia de los Data Lakes

Los Data Lakes surgieron a mediados de los 2000 como soluci√≥n a las limitaciones del Warehouse, impulsados por el software open source (**Hadoop**) y hardware commodity (barato).

![Figura 1-6: Arquitectura t√≠pica de data lake con copias crudas de datos](f16%201.png)

Aqu√≠ tienes la explicaci√≥n simplificada de los componentes clave que dieron origen a los primeros **Data Lakes** y c√≥mo evolucionaron.

### La Primera Generaci√≥n de Data Lakes (Hadoop)

El ecosistema **Hadoop** fue la base de los Data Lakes originales. Permiti√≥ almacenar y procesar **grandes vol√∫menes de datos crudos** a bajo costo.

##### 1. HDFS (Hadoop Distributed File System)

- **¬øQu√© es?** Es el **sistema de almacenamiento distribuido**.
    
- **Funcionamiento Sencillo:** Toma un archivo gigante, lo parte en **peque√±os bloques** (ej. 128 MB) y guarda copias de esos bloques en varias m√°quinas baratas (**escala horizontal**). Si una m√°quina falla, el dato sigue seguro.
    
- **Problema Principal:**
    
    - **Archivos Peque√±os:** Funciona mal si tienes millones de archivos muy peque√±os (unos pocos KB), porque el sistema que rastrea los metadatos (_NameNode_) se satura y se vuelve muy lento.
        
    - **Inmutabilidad:** Los datos son casi **inmutables** (solo puedes a√±adir al final, no puedes actualizar o borrar f√°cilmente un dato en medio del archivo). Esto es un dolor de cabeza para tareas como llevar el historial de clientes (**SCDs**).
        

##### 2. MapReduce

- **¬øQu√© es?** El **modelo de programaci√≥n** para procesar los datos almacenados en HDFS.
    
- **Funcionamiento Sencillo:** Divide la tarea en tres etapas: **Map** (divide el problema), **Shuffle** (intercambia datos entre las m√°quinas), y **Reduce** (combina los resultados).
    
- **Problema Principal:** Es **muy lento** porque en cada etapa tiene que leer y escribir datos en el **disco duro** (E/S intensa).
    

##### 3. Apache Hive

- **¬øQu√© es?** Un **traductor de SQL** para Hadoop.
    
- **Funcionamiento Sencillo:** Te permite escribir consultas **SQL** (_HiveQL_) y Hive las traduce autom√°ticamente a los lentos trabajos **MapReduce**.
    
- **Concepto Clave (Schema-on-read):** Los datos se almacenan sin un esquema estricto, y el esquema se aplica **solo cuando los lees**. Esto te da flexibilidad, pero si no modelas bien los datos, el an√°lisis ser√° ca√≥tico y lento.
    
- **Metastore:** Es el **√≠ndice central** que dice d√≥nde est√°n guardadas las tablas y qu√© columnas tienen. Esto sigue siendo vital hoy.
    


#### üöÄ El Proyecto Spark (La Evoluci√≥n)

**Apache Spark** naci√≥ para resolver la principal limitaci√≥n de Hadoop: la lentitud de MapReduce.

- **Diferencia Clave:** Utiliza el procesamiento **en memoria (RAM)**. En lugar de leer y escribir en el disco en cada paso (como hac√≠a MapReduce), Spark lee los datos una vez, hace todo el procesamiento en la RAM (que es **mucho m√°s r√°pida**), y solo escribe el resultado final al disco.
    
- **Resultado:** Es **hasta 100 veces m√°s r√°pido** que MapReduce.
    
- **Limitaci√≥n:** Necesita un tiempo inicial (_cold start_) para cargar los datos en memoria antes de poder empezar a procesar a alta velocidad.
    

#### üí° Aprendizajes de los Data Lakes (El Problema)

Los Data Lakes lograron almacenar todo tipo de datos de forma barata, pero no resolvieron el problema de **hacer que esos datos fueran valiosos**.

- **Desaf√≠os:**
    
    - **Latencia:** Las consultas no eran lo suficientemente r√°pidas.
        
    - **Falta de Transaccionalidad (ACID):** No pod√≠an garantizar la integridad de los datos ni soportar actualizaciones f√°ciles como un Data Warehouse.
        
    - **Complejidad:** La soluci√≥n termin√≥ siendo tener el **Data Lake** para almacenar lo crudo y el **Data Warehouse** para el consumo final, lo que es costoso y dif√≠cil de mantener (el "patr√≥n de dos niveles").


## Una Breve Historia de la Arquitectura Lakehouse

La arquitectura **Lakehouse** combina lo mejor de ambos mundos: la escalabilidad y flexibilidad del Data Lake (almacenamiento en objetos en la nube barato) con la confiabilidad y rendimiento del Data Warehouse (transacciones ACID).

![Figura 1-8: Arquitectura t√≠pica de lakehouse, con una representaci√≥n de las capas Bronce, Plata y Oro incluidas](f18%201.png)

### Fundadores de Spark y Databricks
Los creadores de Spark fundaron **Databricks** en 2013. A diferencia de sus competidores (Cloudera/Hortonworks que se enfocaron en on-premise), Databricks apost√≥ por la **Nube** y la separaci√≥n de c√≥mputo y almacenamiento.

### Evoluci√≥n Tecnol√≥gica
*   **Almacenamiento de Objetos:** Reemplazo de HDFS por S3 (AWS), ADLS (Azure), GCS (Google). M√°s barato y escala a petabytes.
*   **Spark en la Nube:** Clusters el√°sticos que se crean y destruyen seg√∫n demanda (Kubernetes), sin estar atados a un cluster f√≠sico gigante.

### Emergencia de Formatos de Tabla Abiertos (Open Table Formats)
Para solucionar la falta de transacciones ACID y la gesti√≥n de metadatos en los Data Lakes, surgieron nuevos formatos:

1.  **Apache Hudi (2017, Uber):** Enfocado en upserts eficientes.
2.  **Apache Iceberg (2018, Netflix):** Enfocado en correcci√≥n y rendimiento en grandes escalas.
3.  **Delta Lake (2019, Databricks):** Trajo transacciones ACID, manejo escalable de metadatos, unificaci√≥n de batch/streaming y "Time Travel". Usa archivos **Parquet** m√°s una capa de metadatos transaccionales.

#### C√≥mo funciona Delta Lake
Usa un **Transaction Log (DeltaLog)**.

*   Cada cambio (insert, update, delete) se registra como un commit at√≥mico en archivos JSON secuenciales (`000000.json`).
*   Permite **Time Travel**: Consultar c√≥mo estaba la tabla en el pasado.
*   Usa archivos Parquet para los datos f√≠sicos.

![Figura 1-7: Ejemplo de c√≥mo Delta Lake estructura sus datos y registro de transacciones](f17%201.png)

### Proveedores de Lakehouse
El mercado ha adoptado el concepto:

*   **Databricks:** Pionero, fuerte integraci√≥n Spark + Delta Lake.
*   **Microsoft Fabric / Synapse / HDInsight:** Integran Spark y Delta.
*   **Snowflake, AWS, Google:** Tambi√©n han adoptado terminolog√≠a y funcionalidades Lakehouse.
*   **Cloudera, Dremio, Starburst:** Ofrecen plataformas sobre estos formatos abiertos.

## Arquitectura Medallion y sus Desaf√≠os Pr√°cticos
Databricks y Microsoft promueven la Arquitectura Medallion como la mejor pr√°ctica para organizar datos en este entorno.
Sin embargo, el libro se√±ala un problema cr√≠tico: **Falta de orientaci√≥n pr√°ctica**.

*   Aunque los t√©rminos Bronce/Plata/Oro suenan bien, no hay consenso universal sobre qu√© transformaci√≥n exacta ocurre en cada capa.
*   La confusi√≥n sobre el modelado de datos persiste. ¬øD√≥nde aplico reglas de negocio? ¬øD√≥nde hago *joins*?

### Conclusi√≥n del Cap√≠tulo
Hemos evolucionado de almacenes r√≠gidos on-premise a sistemas distribuidos y flexibles en la nube.

*   **Data Warehouse:** Gran control, gran rendimiento, dif√≠cil escalado, caro.
*   **Data Lake:** Gran escalado, barato, dif√≠cil gesti√≥n y calidad (pantano de datos).
*   **Lakehouse:** Intenta unificar ambos mediante formatos de tabla modernos (Delta, Iceberg) y motores r√°pidos (Spark).

El desaf√≠o actual no es solo tecnol√≥gico, sino de **dise√±o y modelado**. La velocidad de entrega exigida por el negocio presiona a los equipos a saltarse el modelado (a veces bajo la excusa de "Data Mesh" mal implementado), creando silos y deuda t√©cnica. La Arquitectura Medallion ofrece un marco, pero requiere una ejecuci√≥n disciplinada que se detallar√° en los pr√≥ximos cap√≠tulos (2 y 3) del libro.
