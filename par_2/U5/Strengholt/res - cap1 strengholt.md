---
title: "Building Medallion Architectures - Designing with Delta Lake and Spark"
subtitle: "Resumen del cap√≠tulo 1"
author: "Piethein Strengholt"
date: \today
geometry: margin=1.6in
colorlinks: true
header-includes:
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
  - \usepackage{graphicx}
	# - \setkeys{Gin}{width=0.95\textwidth}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{tabularx}
  - \usepackage{array}
  - \renewcommand{\arraystretch}{1.5}
  
  # neutralizamos tightlist y ajustamos espaciado de listas
  - \let\tightlist\relax
  - \usepackage{enumitem}
  - \setlist[itemize,enumerate]{itemsep=1\baselineskip, topsep=1\baselineskip}
  
  # estilo rosado p√°lido con fuente aclarada
  - \usepackage[most]{tcolorbox}
  - |
    \newtcolorbox{noteBox}{
      colback=red!5!white,
      colframe=red!30!black,
      coltext=black!70,        % color del texto menos saturado
      arc=4pt,
      left=6pt, right=6pt, top=4pt, bottom=4pt,
      boxrule=0.5pt,
      breakable
    }
  - |
    \renewenvironment{quote}{\begin{noteBox}}{\end{noteBox}}

  # --- Caption sin numeraci√≥n para figuras ---
  - \usepackage{caption}
  - \captionsetup[figure]{labelformat=empty}
---

# Cap√≠tulo 1. La Evoluci√≥n de la Arquitectura de Datos

Crear una arquitectura de datos robusta es uno de los aspectos m√°s desafiantes de la gesti√≥n de datos. El proceso abarca desde la recolecci√≥n hasta la transformaci√≥n, distribuci√≥n y consumo final, variando seg√∫n la gobernanza, herramientas, perfil de riesgo y madurez de la organizaci√≥n.

A pesar de estas diferencias, el autor propone una met√°fora fundamental para estructurar cualquier estrategia de datos: el **Dise√±o de Arquitectura de Tres Capas**.

![Figura 1-1: El dise√±o de arquitectura de tres capas](f11%203.png)

Este dise√±o consta de:

### 1. üßë‚Äçüíª Capa 1: Proveedores de Datos (**Data Providers**)

- **¬øQu√© es?** Son los **puntos de origen** de todos los datos.
    
- **En la pr√°ctica:** Es donde est√° la informaci√≥n bruta: tus bases de datos operacionales, los archivos de texto, los datos que vienen de sensores, los registros de aplicaciones, etc.
    
- **Desaf√≠o:** Vienen en **muchos formatos y ubicaciones diferentes** (la "mezcla de tipos de datos, formatos y ubicaciones dispersas").

### Capa 2: Capa de Distribuci√≥n (**Distribution Layer**)

- **¬øQu√© es?** Es el **sistema de transporte y procesamiento**. Es la plataforma donde los datos se mueven, se limpian, se transforman y se preparan.
    
- **En la pr√°ctica:** Aqu√≠ es donde se usan herramientas complejas (como **Apache Spark**) para integrar y procesar grandes vol√∫menes de datos crudos, convirti√©ndolos en algo √∫til.
    
- **Desaf√≠o:** Es la parte **m√°s compleja** porque hay much√≠simas tecnolog√≠as diferentes para hacer esta integraci√≥n (el "Modern Data Stack").

### 3. üìä Capa 3: Consumidores de Datos (**Data Consumers**)

- **¬øQu√© es?** Son los **usuarios finales** y las **aplicaciones** que necesitan la informaci√≥n lista para tomar decisiones.
    
- **En la pr√°ctica:** Son los paneles de control (**BI**), los modelos de **Machine Learning (ML)** para hacer predicciones, y los sistemas de **Inteligencia Artificial (AI)** que automatizan acciones.


### Capa Transversal: üõ°Ô∏è Metadatos y Gobernanza

- **¬øQu√© es?** Es la **supervisi√≥n y las reglas** que controlan todas las capas.
    
- **En la pr√°ctica:** Se asegura de que los datos sean **seguros**, que sean de **calidad** (no tengan errores) y que todo el mundo sepa **qu√© significa** cada dato (metadatos).
    

### El Desaf√≠o Actual

El texto menciona el **"Modern Data Stack"** como el problema clave hoy en d√≠a.

- **Problema:** Este "Stack" est√° hecho de **muchas herramientas individuales** (para almacenamiento, procesamiento, etc.) que no siempre se hablan bien entre s√≠. Esto hace que sea muy **dif√≠cil y costoso** para las empresas crear una plataforma de distribuci√≥n funcional.
    
- **Soluci√≥n:** La **Arquitectura Medallion** (que usa tecnolog√≠as como Spark y Delta Lake) surge como una forma de **estandarizar** esta Capa de Distribuci√≥n, simplificando el proceso y mejorando la calidad de los datos. En resumen: **Los datos nacen (Proveedores), se preparan (Distribuci√≥n) y se usan (Consumidores), todo bajo la vigilancia de la Gobernanza.**

## ¬øQu√© es una Arquitectura Medallion?

Es un patr√≥n de dise√±o de datos utilizado para organizar l√≥gicamente los datos, generalmente en un *Lakehouse*. Su objetivo es mejorar incremental y progresivamente la estructura y calidad de los datos a medida que fluyen a trav√©s de tres capas principales.

| Capa | Descripci√≥n y Funci√≥n |
| :--- | :--- |
| **Bronze (Bronce)** | Almacena datos crudos (raw) de varias fuentes en su estructura nativa. Sirve como registro hist√≥rico y almacenamiento inicial confiable. |
| **Silver (Plata)** | Refina y estandariza los datos crudos. Aplica deduplicaci√≥n, limpieza y validaci√≥n. Act√∫a como etapa transicional para datos granulares y consistentes. |
| **Gold (Oro)** | Optimiza los datos refinados para insights de negocio espec√≠ficos. Agrega, resume y enriquece datos para reportes de alto nivel y anal√≠tica, priorizando el rendimiento. |

![Figura 1-2: Una arquitectura Medallion, que organiza los datos en tres capas, mejorando la estructura y calidad de los datos a medida que avanza a trav√©s de las capas](f12%202.png)

Aunque las etiquetas son intuitivas, muchas empresas fallan al modelar sus datos dentro de estas capas, confundiendo objetivos y estrategias de gobernanza. Para entender c√≥mo aplicar esto correctamente, es vital comprender primero la historia de las arquitecturas de datos.

## Una Breve Historia de la Arquitectura de Data Warehouse

En los a√±os 90, el **Data Warehousing** surgi√≥ para crear una "versi√≥n √∫nica de la verdad" integrando datos en una colecci√≥n unificada.

![Figura 1-3: Arquitectura t√≠pica de un data warehouse](f13%202.png)

La arquitectura cl√°sica fluye de izquierda a derecha:

1.  **Sistemas OLTP (Fuentes)**.
2.  **Staging Area (√Årea de preparaci√≥n)**.
3.  **Data Warehouse (Almac√©n central)**.
4.  **Data Marts (Presentaci√≥n)**.

### Sistemas OLTP (Online Transaction Processing)
La mayor√≠a de los sistemas fuente son transaccionales. Sus cargas de trabajo son predecibles (leer, actualizar o borrar un registro).

*   **Dise√±o:** Est√°n altamente **normalizados** (generalmente 3NF - Tercera Forma Normal) para reducir redundancia y asegurar la integridad de los datos.
*   **Propiedades ACID:** Atomicidad, Consistencia, Aislamiento, Durabilidad. Cruciales para transacciones bancarias u operativas.
*   **Problema para anal√≠tica:** Extraer datos para consultas complejas (que requieren muchos *joins*) es dif√≠cil y sobrecarga el sistema. Adem√°s, los OLTP suelen borrar datos antiguos para mantener el rendimiento, perdiendo historia valiosa.

### Normalizaci√≥n de Base de Datos vs. Desnormalizaci√≥n
*   **Normalizaci√≥n:** Reestructuraci√≥n para reducir redundancia. Eficiente para almacenamiento y mantenimiento (escrituras), pero complejo para lecturas masivas.
*   **Desnormalizaci√≥n:** Introducir redundancia intencional para mejorar el rendimiento de las consultas (lecturas), reduciendo la necesidad de *joins*. Com√∫n en Data Warehousing.

### Data Warehouses
El Data Warehouse es el hub central para **OLAP (Online Analytical Processing)**.

*   A diferencia de OLTP, aqu√≠ se optimiza para el rendimiento anal√≠tico (lecturas repetidas).
*   Los datos suelen estar **desnormalizados**: tablas grandes, aplanadas y con datos duplicados para facilitar diferentes patrones de lectura.

### El √Årea de Staging (Staging Area)
Es el paso intermedio entre la fuente y el warehouse.

*   **Funci√≥n:** Extracci√≥n (parte del ETL). Puede ser una base de datos relacional o almacenamiento de archivos (m√°s barato).
*   **Importancia:** Permite guardar copias hist√≥ricas de las entregas de datos, √∫til si el warehouse se corrompe y necesita reconstruirse. A√≠sla el proceso de extracci√≥n de las transformaciones complejas.

### Metodolog√≠a Inmon
Creada por Bill Inmon (dise√±o **Top-Down**).

1.  Se extraen datos al Staging.
2.  Se cargan en un **Enterprise Data Warehouse (EDW)** centralizado con un modelo **normalizado (3NF)**.
3.  Luego, se crean **Data Marts** departamentales derivados del EDW, usualmente desnormalizados (esquemas de estrella) para reportes.

*   **Desventaja:** Doble esfuerzo de ETL (Fuente -> EDW Normalizado -> Data Mart Desnormalizado). Mayor tiempo de desarrollo y redundancia.

![Figura 1-4: El enfoque Inmon; un dise√±o de arriba hacia abajo donde primero se construye un almac√©n de datos centralizado y luego se crean data marts a partir de este almac√©n central](f14%201.png)

### Metodolog√≠a Kimball
Creada por Ralph Kimball (dise√±o **Bottom-Up**). Introducida en 1996.

*   Se enfoca en tablas dimensionales para procesamiento anal√≠tico eficiente.
*   Utiliza el **Modelo Dimensional (Esquema de Estrella)**: Tablas de Hechos (m√©tricas) rodeadas de Tablas de Dimensiones (contexto).
*   La capa de integraci√≥n es una colecci√≥n de tablas dimensionales y tablas de hechos. Los Data Marts son subconjuntos l√≥gicos o f√≠sicos de estas tablas.

![Figura 1-5: La metodolog√≠a Kimball; un enfoque de abajo hacia arriba para construir el data warehouse](f15%201.png)

#### Dimensiones Conformadas y SCDs
Kimball introdujo conceptos clave que a√∫n se usan:

*   **Dimensiones Conformadas:** Dimensiones compartidas y estandarizadas entre diferentes √°reas (ej. una tabla "Tiempo" o "Cliente" id√©ntica para Ventas y Marketing).
*   **SCD (Slowly Changing Dimensions):** T√©cnicas para manejar cambios hist√≥ricos en los datos.

| Tipo SCD | Nombre | Descripci√≥n | Pros/Contras |
| :--- | :--- | :--- | :--- |
| **SCD1** | Sobrescribir (Overwrite) | Actualiza el registro existente con el nuevo valor. | Simple, pero pierde la historia. |
| **SCD2** | A√±adir nueva fila (Add row) | Crea un nuevo registro para el cambio, manteniendo el viejo. Usa claves subrogadas y fechas de vigencia. | Mantiene historia completa. Aumenta el tama√±o de la tabla. |
| **SCD3** | A√±adir nueva columna (Add column) | Agrega una columna para el valor anterior (ej. "Direcci√≥n_Anterior"). | Solo guarda una versi√≥n hist√≥rica limitada. |

### Conclusiones sobre Data Warehouses Tradicionales
Aunque efectivos para datos estructurados y consultas r√°pidas (gracias a la integraci√≥n estrecha de hardware y software en sistemas on-premise), tienen problemas de escalabilidad. Escalar verticalmente (m√°s hardware en una m√°quina) es costoso y tiene l√≠mites f√≠sicos. Adem√°s, no manejan bien datos no estructurados o ML.

## Una Breve Historia de los Data Lakes

Los Data Lakes surgieron a mediados de los 2000 como soluci√≥n a las limitaciones del Warehouse, impulsados por el software open source (**Hadoop**) y hardware commodity (barato).

![Figura 1-6: Arquitectura t√≠pica de data lake con copias crudas de datos](f16%201.png)

### Hadoop y sus Componentes
El ecosistema Hadoop fue la base de la primera generaci√≥n de Data Lakes:

1.  **HDFS (Hadoop Distributed File System):**
    *   Sistema de archivos distribuido. Divide archivos grandes en bloques (ej. 128 MB) y los replica en varios nodos para tolerancia a fallos.
    *   Escala horizontalmente (a√±adir m√°s m√°quinas baratas).
    *   **Problema de archivos peque√±os:** HDFS est√° optimizado para archivos grandes. Muchos archivos peque√±os (KB) saturan la memoria del *NameNode* (que guarda los metadatos) y matan el rendimiento.
    *   **Inmutabilidad:** Los bloques son inmutables (solo *append*). No se puede hacer un "UPDATE" de SQL tradicional; se debe reescribir el archivo o gestionar logs complejos, dificultando la implementaci√≥n de SCDs.

2.  **MapReduce:**
    *   Modelo de programaci√≥n para procesar datos en paralelo. Fases: *Map* (dividir), *Shuffle* (ordenar/transferir), *Reduce* (agregar).
    *   **Problema:** Muy lento debido a la intensa lectura/escritura en disco en cada etapa.

3.  **Apache Hive:**
    *   Capa SQL sobre Hadoop. Traduce consultas *HiveQL* a trabajos MapReduce.
    *   **Schema-on-read:** Permite guardar datos sin esquema definido y aplicarlo al leer. Esto da flexibilidad pero **NO** elimina la necesidad de modelado de datos (un error com√∫n). Sin modelado, el rendimiento y la integraci√≥n sufren.
    *   **Metastore:** Repositorio central de metadatos (tablas, columnas, ubicaci√≥n) que persiste hasta hoy en arquitecturas modernas.

### Proyecto Spark
Nacido en 2009 en UC Berkeley para solucionar la lentitud de MapReduce.

*   **Diferencia clave:** Procesamiento **en memoria**. Lee del disco una vez, procesa en RAM y escribe el resultado. Hasta 100 veces m√°s r√°pido que MapReduce.
*   **Spark SQL:** Reemplaz√≥ a Shark, manteniendo compatibilidad con Hive Metastore.
*   **Limitaci√≥n:** Tiene un tiempo de inicio (*cold start*). Necesita cargar datos del disco a memoria antes de ser r√°pido.

### Aprendizajes de los Data Lakes
Los Data Lakes son excelentes para almacenar vol√∫menes masivos de datos crudos (estructurados y no estructurados) a bajo costo. Sin embargo, transformarlos para entregar valor de negocio es complejo. Tienen problemas de latencia, falta de soporte transaccional (ACID) y rendimiento de consultas. Esto llev√≥ al patr√≥n de "dos niveles": Data Lake para almacenamiento + Data Warehouse para consumo, lo cual es complejo de mantener.

## Una Breve Historia de la Arquitectura Lakehouse

La arquitectura **Lakehouse** combina lo mejor de ambos mundos: la escalabilidad y flexibilidad del Data Lake (almacenamiento en objetos en la nube barato) con la confiabilidad y rendimiento del Data Warehouse (transacciones ACID).

![Figura 1-8: Arquitectura t√≠pica de lakehouse, con una representaci√≥n de las capas Bronce, Plata y Oro incluidas](f18%201.png)

### Fundadores de Spark y Databricks
Los creadores de Spark fundaron **Databricks** en 2013. A diferencia de sus competidores (Cloudera/Hortonworks que se enfocaron en on-premise), Databricks apost√≥ por la **Nube** y la separaci√≥n de c√≥mputo y almacenamiento.

### Evoluci√≥n Tecnol√≥gica
*   **Almacenamiento de Objetos:** Reemplazo de HDFS por S3 (AWS), ADLS (Azure), GCS (Google). M√°s barato y escala a petabytes.
*   **Spark en la Nube:** Clusters el√°sticos que se crean y destruyen seg√∫n demanda (Kubernetes), sin estar atados a un cluster f√≠sico gigante.

### Emergencia de Formatos de Tabla Abiertos (Open Table Formats)
Para solucionar la falta de transacciones ACID y la gesti√≥n de metadatos en los Data Lakes, surgieron nuevos formatos:

1.  **Apache Hudi (2017, Uber):** Enfocado en upserts eficientes.
2.  **Apache Iceberg (2018, Netflix):** Enfocado en correcci√≥n y rendimiento en grandes escalas.
3.  **Delta Lake (2019, Databricks):** Trajo transacciones ACID, manejo escalable de metadatos, unificaci√≥n de batch/streaming y "Time Travel". Usa archivos **Parquet** m√°s una capa de metadatos transaccionales.

#### C√≥mo funciona Delta Lake
Usa un **Transaction Log (DeltaLog)**.

*   Cada cambio (insert, update, delete) se registra como un commit at√≥mico en archivos JSON secuenciales (`000000.json`).
*   Permite **Time Travel**: Consultar c√≥mo estaba la tabla en el pasado.
*   Usa archivos Parquet para los datos f√≠sicos.

![Figura 1-7: Ejemplo de c√≥mo Delta Lake estructura sus datos y registro de transacciones](f17%201.png)

### Proveedores de Lakehouse
El mercado ha adoptado el concepto:

*   **Databricks:** Pionero, fuerte integraci√≥n Spark + Delta Lake.
*   **Microsoft Fabric / Synapse / HDInsight:** Integran Spark y Delta.
*   **Snowflake, AWS, Google:** Tambi√©n han adoptado terminolog√≠a y funcionalidades Lakehouse.
*   **Cloudera, Dremio, Starburst:** Ofrecen plataformas sobre estos formatos abiertos.

## Arquitectura Medallion y sus Desaf√≠os Pr√°cticos
Databricks y Microsoft promueven la Arquitectura Medallion como la mejor pr√°ctica para organizar datos en este entorno.
Sin embargo, el libro se√±ala un problema cr√≠tico: **Falta de orientaci√≥n pr√°ctica**.

*   Aunque los t√©rminos Bronce/Plata/Oro suenan bien, no hay consenso universal sobre qu√© transformaci√≥n exacta ocurre en cada capa.
*   La confusi√≥n sobre el modelado de datos persiste. ¬øD√≥nde aplico reglas de negocio? ¬øD√≥nde hago *joins*?

### Conclusi√≥n del Cap√≠tulo
Hemos evolucionado de almacenes r√≠gidos on-premise a sistemas distribuidos y flexibles en la nube.

*   **Data Warehouse:** Gran control, gran rendimiento, dif√≠cil escalado, caro.
*   **Data Lake:** Gran escalado, barato, dif√≠cil gesti√≥n y calidad (pantano de datos).
*   **Lakehouse:** Intenta unificar ambos mediante formatos de tabla modernos (Delta, Iceberg) y motores r√°pidos (Spark).

El desaf√≠o actual no es solo tecnol√≥gico, sino de **dise√±o y modelado**. La velocidad de entrega exigida por el negocio presiona a los equipos a saltarse el modelado (a veces bajo la excusa de "Data Mesh" mal implementado), creando silos y deuda t√©cnica. La Arquitectura Medallion ofrece un marco, pero requiere una ejecuci√≥n disciplinada que se detallar√° en los pr√≥ximos cap√≠tulos (2 y 3) del libro.
